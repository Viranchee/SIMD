{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "The goal is to write Kernels targeting CPU, SIMD, GPU, Python/C/C++ etc and do a performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.cpp_extension import load_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonCppHeader = \"\"\"\n",
    "#include <torch/extension.h>\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <arm_neon.h>\n",
    "using namespace std;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAddCppNeon = \"\"\"\n",
    "void vectorAddNeon(uint8_t* a, uint8_t* b, uint8_t* c, int n) {\n",
    "  for (int i = 0; i < n; i += 16) {\n",
    "    uint8x16_t va = vld1q_u8(a + i);\n",
    "    uint8x16_t vb = vld1q_u8(b + i);\n",
    "    uint8x16_t vc = vaddq_u8(va, vb);\n",
    "    vst1q_u8(c + i, vc);\n",
    "  }\n",
    "}\n",
    "\n",
    "void printHi(string str=\"Hi\") {\n",
    "  cout << str << endl;\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAddModule = load_inline(\n",
    "  name='vectorAddNeonModule',\n",
    "  cpp_sources=[commonCppHeader, vectorAddCppNeon],\n",
    "  functions=['vectorAddNeon', 'printHi'],\n",
    "  verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.utils.cpp_extension.include_paths()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAddModule.printHi(\"LMFAO\")\n",
    "a = torch.randint(0, 20, (100,), dtype=torch.uint8)\n",
    "b = torch.randint(0, 20, (100,), dtype=torch.uint8)\n",
    "c = torch.zeros(100, dtype=torch.uint8)\n",
    "# # Pass pointers of a,b,c to the C++ function\n",
    "vectorAddModule.vectorAddNeon(a.data_ptr(), b.data_ptr(), c.data_ptr(), 100)\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timePyTorchFunction(f, input):\n",
    "  start = torch.mps.Event(enable_timing=True)\n",
    "  end = torch.mps.Event(enable_timing=True)\n",
    "  for _ in range(5):\n",
    "    f(input)\n",
    "  start.record()\n",
    "  for _ in range(1000):\n",
    "    f(input)\n",
    "  end.record()\n",
    "  torch.mps.synchronize()\n",
    "  return start.elapsed_time(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "  return x * x\n",
    "\n",
    "def square_2(x):\n",
    "  return x ** 2\n",
    "\n",
    "def identity(x):\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a Pytorch Int32 array\n",
    "b = torch.randint(0, 1000, (10000,), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "timePyTorchFunction() takes 2 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m times[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython x ** 2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m timePyTorchFunction(square, b)\n\u001b[1;32m      4\u001b[0m times[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx * x\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m timePyTorchFunction(square_2, b)\n\u001b[0;32m----> 5\u001b[0m times[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtimePyTorchFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43msquareInt32Module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare_int32_neon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m times\n",
      "\u001b[0;31mTypeError\u001b[0m: timePyTorchFunction() takes 2 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "times = {}\n",
    "times[\"torch.square\"] = timePyTorchFunction(torch.square, b)\n",
    "times[\"Python x ** 2\"] = timePyTorchFunction(square, b)\n",
    "times[\"x * x\"] = timePyTorchFunction(square_2, b)\n",
    "times[\"neon\"] = timePyTorchFunction(squareInt32Module.square_int32_neon, b.data_ptr(), c.data_ptr(), 10000, b)\n",
    "\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /Users/viranchee/Library/Caches/torch_extensions/py39_cpu as PyTorch extensions root...\n",
      "The input conditions for extension module squareInt32NeonModule have changed. Bumping to version 3 and re-building as squareInt32NeonModule_v3...\n",
      "Emitting ninja build file /Users/viranchee/Library/Caches/torch_extensions/py39_cpu/squareInt32NeonModule/build.ninja...\n",
      "Building extension module squareInt32NeonModule_v3...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=squareInt32NeonModule_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -isystem /Volumes/code/env/pymetal/lib/python3.9/site-packages/torch/include -isystem /Volumes/code/env/pymetal/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /Users/viranchee/Library/Caches/torch_extensions/py39_cpu/squareInt32NeonModule/main.cpp -o main.o \n",
      "[2/2] c++ main.o -shared -L/Volumes/code/env/pymetal/lib/python3.9/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -undefined dynamic_lookup -o squareInt32NeonModule_v3.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module squareInt32NeonModule_v3...\n"
     ]
    }
   ],
   "source": [
    "# write a Neon square C++ function\n",
    "\n",
    "squareInt32CppNeon = \"\"\"\n",
    "void square_neon(int32_t* input, int32_t* output, int64_t size) {\n",
    "    int64_t i = 0;\n",
    "\n",
    "    // Vectorized processing using ARM NEON for int32\n",
    "    for (; i <= size - 4; i += 4) {\n",
    "        int32x4_t v = vld1q_s32(input + i);  // Load 4 int32 values\n",
    "        int32x4_t v_sq = vmulq_s32(v, v);    // Square each element\n",
    "        vst1q_s32(output + i, v_sq);         // Store back to memory\n",
    "    }\n",
    "\n",
    "    // Handle remaining elements\n",
    "    for (; i < size; i++) {\n",
    "        output[i] = input[i] * input[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Wrapper function to receive pointers as integers from Python\n",
    "void square_int32_neon(uintptr_t input_ptr, uintptr_t output_ptr, int64_t size) {\n",
    "    int32_t* input = reinterpret_cast<int32_t*>(input_ptr);\n",
    "    int32_t* output = reinterpret_cast<int32_t*>(output_ptr);\n",
    "\n",
    "    square_neon(input, output, size);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "squareInt32Module = load_inline(\n",
    "  name='squareInt32NeonModule',\n",
    "  cpp_sources=[commonCppHeader, squareInt32CppNeon],\n",
    "  functions=['square_int32_neon'],\n",
    "  verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.zeros(10000, dtype=torch.int32)\n",
    "if (b.is_contiguous() == False):\n",
    "  b = b.contiguous()\n",
    "squareInt32Module.square_int32_neon(b.data_ptr(), c.data_ptr(), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with torch.autograd.profiler.profile(use_cpu=True) as prof:\n",
    "  squareInt32Module.square_int32_neon(b.data_ptr(), c.data_ptr(), 10000)\n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"cpu_time\", row_limit=10))\n",
    "prof.key_averages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof.key_averages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(torch.all(c == b * b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymetal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
